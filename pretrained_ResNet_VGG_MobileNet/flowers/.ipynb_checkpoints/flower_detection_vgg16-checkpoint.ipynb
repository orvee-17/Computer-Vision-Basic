{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flower Classification with pre- trained VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\TOOLS\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From D:\\TOOLS\\Anaconda\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img_row = 128\n",
    "img_col = 128\n",
    "\n",
    "VGG = VGG16(weights='imagenet', include_top=False, input_shape=(img_row,img_col,3)) #taking pretrained weights;top layer chopped off as i am going to use it of my own;\n",
    "\n",
    "for layer in VGG.layers:\n",
    "    layer.trainable= False #we want to keep the weights non-trainable; true dile layers gula freeze hobe na."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTopModelVGG(bottom_model, num_classes):          #our customized topmodel as we chopped VGG16's top model ;here bottom_model means our vgg16\n",
    "\n",
    "    top_model = bottom_model.output #output of vgg16 last layer taken as input here\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "    top_model = Dense(1024,activation='relu')(top_model) #24=79% accuracy\n",
    "    top_model = Dense(1024,activation='relu')(top_model)\n",
    "    top_model = Dense(128,activation='relu')(top_model)\n",
    "    top_model = Dense(128,activation='relu')(top_model)\n",
    "    top_model = Dense(64,activation='relu')(top_model)\n",
    "    top_model = Dense(num_classes,activation='softmax')(top_model)\n",
    "\n",
    "    return top_model\n",
    "\n",
    "num_classes = 5 #2 classes\n",
    "\n",
    "FC_Head = addTopModelVGG(VGG,num_classes)  #gives the top layer for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = VGG.input, outputs = FC_Head) #this is our customized model which contains vgg16 and then our own made fully connected layer in the output side; MODEL is imported from keras.models;\n",
    "                                                      #VGG.input means the i/p we get from vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 16,445,893\n",
      "Trainable params: 1,731,205\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data_dir = 'test'\n",
    "train_data_dir = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print (os.listdir(train_data_dir))\n",
    "print ((os.listdir(test_data_dir)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3598 images belonging to 5 classes.\n",
      "Found 727 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(           #Using data Augmentation\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=30,\n",
    "                    width_shift_range=0.3,\n",
    "                    height_shift_range=0.3,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest'\n",
    "                                   )\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                        train_data_dir,\n",
    "                        target_size = (img_row,img_col),\n",
    "                        batch_size = batch_size,\n",
    "                        class_mode = 'categorical',  #for multiclass, class_mode='categorical'\n",
    "                        shuffle=True  #shuffles the training data\n",
    "                         )\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "                            test_data_dir,\n",
    "                            target_size=(img_row,img_col),\n",
    "                            batch_size=batch_size,\n",
    "                            class_mode='categorical',\n",
    "                            shuffle=True )  #similarly here too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop,Adam    #import activation function that you need\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau \n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "                             'flower_detection_vgg_weight_2.h5',  #name by which the weight will be save, we later use this file in test set\n",
    "                             monitor='val_loss',\n",
    "                             mode='min',\n",
    "                             save_best_only=True,  #this means whenever we get min. validation loss, the model will be saved\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(                      #this monitors val_loss upto 10 epochs as patience=10 and stops the training if validation loss is not decreasing \n",
    "                          monitor='val_loss',\n",
    "                          min_delta=0,\n",
    "                          restore_best_weights=True,\n",
    "                          patience=20,\n",
    "                          verbose=1)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', #helps to monitor if val_loss;if it doesn't reduce after 5 epochs, the learning rate will be decreased and checked again in the same way;this will be done upto lr=.001\n",
    "                                            patience=5, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.2, \n",
    "                                            min_lr=0.0001)\n",
    "\n",
    "callbacks = [earlystop,checkpoint,learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = 3598 #no of training image we have\n",
    "nb_validation_samples = 727  #no of test image we have\n",
    "\n",
    "epochs = 40\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',  #since only two class\n",
    "              optimizer=Adam(lr=0.001),  #so ei learning rate diye shuru hobe and decrease kore .0001 porjonto dekhbe due to the callback learning_rate_reduction function\n",
    "              metrics=['accuracy']\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "56/56 [==============================] - 95s 2s/step - loss: 1.3520 - accuracy: 0.4290 - val_loss: 0.9402 - val_accuracy: 0.5568\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.94023, saving model to flower_detection_vgg_weight_2.h5\n",
      "Epoch 2/40\n",
      "56/56 [==============================] - 94s 2s/step - loss: 0.9890 - accuracy: 0.6150 - val_loss: 0.9651 - val_accuracy: 0.7017\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.94023\n",
      "Epoch 3/40\n",
      "56/56 [==============================] - 95s 2s/step - loss: 0.8673 - accuracy: 0.6719 - val_loss: 0.7949 - val_accuracy: 0.6152\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.94023 to 0.79489, saving model to flower_detection_vgg_weight_2.h5\n",
      "Epoch 4/40\n",
      "56/56 [==============================] - 95s 2s/step - loss: 0.8000 - accuracy: 0.6973 - val_loss: 0.8215 - val_accuracy: 0.7330\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.79489\n",
      "Epoch 5/40\n",
      "56/56 [==============================] - 96s 2s/step - loss: 0.7524 - accuracy: 0.7165 - val_loss: 0.5573 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.79489 to 0.55725, saving model to flower_detection_vgg_weight_2.h5\n",
      "Epoch 6/40\n",
      "56/56 [==============================] - 94s 2s/step - loss: 0.7459 - accuracy: 0.7176 - val_loss: 1.0028 - val_accuracy: 0.7017\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.55725\n",
      "Epoch 7/40\n",
      "56/56 [==============================] - 95s 2s/step - loss: 0.7141 - accuracy: 0.7215 - val_loss: 1.3938 - val_accuracy: 0.6880\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.55725\n",
      "Epoch 8/40\n",
      "56/56 [==============================] - 95s 2s/step - loss: 0.7054 - accuracy: 0.7338 - val_loss: 0.6713 - val_accuracy: 0.7415\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.55725\n",
      "Epoch 9/40\n",
      "56/56 [==============================] - 97s 2s/step - loss: 0.6596 - accuracy: 0.7627 - val_loss: 0.5440 - val_accuracy: 0.7259\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.55725 to 0.54397, saving model to flower_detection_vgg_weight_2.h5\n",
      "Epoch 10/40\n",
      "56/56 [==============================] - 98s 2s/step - loss: 0.6331 - accuracy: 0.7600 - val_loss: 1.3546 - val_accuracy: 0.7159\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.54397\n",
      "Epoch 11/40\n",
      "56/56 [==============================] - 98s 2s/step - loss: 0.6203 - accuracy: 0.7723 - val_loss: 0.7077 - val_accuracy: 0.7551\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.54397\n",
      "Epoch 12/40\n",
      "56/56 [==============================] - 99s 2s/step - loss: 0.6208 - accuracy: 0.7679 - val_loss: 0.5649 - val_accuracy: 0.7045\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.54397\n",
      "Epoch 13/40\n",
      "56/56 [==============================] - 99s 2s/step - loss: 0.6374 - accuracy: 0.7576 - val_loss: 0.6500 - val_accuracy: 0.7085\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.54397\n",
      "Epoch 14/40\n",
      "56/56 [==============================] - 100s 2s/step - loss: 0.6410 - accuracy: 0.7595 - val_loss: 0.7961 - val_accuracy: 0.7188\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.54397\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 15/40\n",
      "56/56 [==============================] - 100s 2s/step - loss: 0.5718 - accuracy: 0.7913 - val_loss: 0.7373 - val_accuracy: 0.7376\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.54397\n",
      "Epoch 16/40\n",
      "56/56 [==============================] - 98s 2s/step - loss: 0.5314 - accuracy: 0.8055 - val_loss: 0.7903 - val_accuracy: 0.7557\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.54397\n",
      "Epoch 17/40\n",
      "56/56 [==============================] - 97s 2s/step - loss: 0.5352 - accuracy: 0.7993 - val_loss: 0.6877 - val_accuracy: 0.7784\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.54397\n",
      "Epoch 18/40\n",
      "56/56 [==============================] - 97s 2s/step - loss: 0.5200 - accuracy: 0.8069 - val_loss: 0.4127 - val_accuracy: 0.7472\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.54397 to 0.41265, saving model to flower_detection_vgg_weight_2.h5\n",
      "Epoch 19/40\n",
      "56/56 [==============================] - 95s 2s/step - loss: 0.5067 - accuracy: 0.8191 - val_loss: 0.6122 - val_accuracy: 0.7872\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.41265\n",
      "Epoch 20/40\n",
      "56/56 [==============================] - 97s 2s/step - loss: 0.5194 - accuracy: 0.8119 - val_loss: 0.5361 - val_accuracy: 0.7443\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.41265\n",
      "Epoch 21/40\n",
      "56/56 [==============================] - 97s 2s/step - loss: 0.4838 - accuracy: 0.8237 - val_loss: 0.4312 - val_accuracy: 0.7726\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.41265\n",
      "Epoch 22/40\n",
      "56/56 [==============================] - 97s 2s/step - loss: 0.4515 - accuracy: 0.8298 - val_loss: 0.4827 - val_accuracy: 0.7642\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.41265\n",
      "Epoch 23/40\n",
      "56/56 [==============================] - 97s 2s/step - loss: 0.4821 - accuracy: 0.8225 - val_loss: 0.3223 - val_accuracy: 0.7726\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.41265 to 0.32234, saving model to flower_detection_vgg_weight_2.h5\n",
      "Epoch 24/40\n",
      "56/56 [==============================] - 96s 2s/step - loss: 0.5152 - accuracy: 0.8106 - val_loss: 1.0613 - val_accuracy: 0.7670\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.32234\n",
      "Epoch 25/40\n",
      "56/56 [==============================] - 96s 2s/step - loss: 0.4862 - accuracy: 0.8145 - val_loss: 1.1957 - val_accuracy: 0.7784\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.32234\n",
      "Epoch 26/40\n",
      "56/56 [==============================] - 104s 2s/step - loss: 0.4839 - accuracy: 0.8192 - val_loss: 0.7204 - val_accuracy: 0.7318\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.32234\n",
      "Epoch 27/40\n",
      "56/56 [==============================] - 100s 2s/step - loss: 0.4569 - accuracy: 0.8265 - val_loss: 0.7858 - val_accuracy: 0.7983\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.32234\n",
      "Epoch 28/40\n",
      "56/56 [==============================] - 99s 2s/step - loss: 0.4488 - accuracy: 0.8213 - val_loss: 0.4407 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.32234\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 29/40\n",
      "56/56 [==============================] - 96s 2s/step - loss: 0.4750 - accuracy: 0.8191 - val_loss: 0.5601 - val_accuracy: 0.7841\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.32234\n",
      "Epoch 30/40\n",
      "56/56 [==============================] - 106s 2s/step - loss: 0.4494 - accuracy: 0.8292 - val_loss: 0.7799 - val_accuracy: 0.7259\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.32234\n",
      "Epoch 31/40\n",
      "56/56 [==============================] - 108s 2s/step - loss: 0.4216 - accuracy: 0.8443 - val_loss: 0.8062 - val_accuracy: 0.7528\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.32234\n",
      "Epoch 32/40\n",
      "56/56 [==============================] - 102s 2s/step - loss: 0.4384 - accuracy: 0.8422 - val_loss: 0.4684 - val_accuracy: 0.7930\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.32234\n",
      "Epoch 33/40\n",
      "56/56 [==============================] - 97s 2s/step - loss: 0.4485 - accuracy: 0.8309 - val_loss: 0.7178 - val_accuracy: 0.7528\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.32234\n",
      "Epoch 34/40\n",
      "56/56 [==============================] - 96s 2s/step - loss: 0.4345 - accuracy: 0.8337 - val_loss: 0.4327 - val_accuracy: 0.7609\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.32234\n",
      "Epoch 35/40\n",
      "56/56 [==============================] - 97s 2s/step - loss: 0.4390 - accuracy: 0.8298 - val_loss: 0.6427 - val_accuracy: 0.8097\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.32234\n",
      "Epoch 36/40\n",
      "56/56 [==============================] - 95s 2s/step - loss: 0.4254 - accuracy: 0.8410 - val_loss: 0.4436 - val_accuracy: 0.7843\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.32234\n",
      "Epoch 37/40\n",
      "56/56 [==============================] - 98s 2s/step - loss: 0.4259 - accuracy: 0.8449 - val_loss: 0.4577 - val_accuracy: 0.7301\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.32234\n",
      "Epoch 38/40\n",
      "56/56 [==============================] - 95s 2s/step - loss: 0.4312 - accuracy: 0.8416 - val_loss: 1.2974 - val_accuracy: 0.8017\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.32234\n",
      "Epoch 39/40\n",
      "56/56 [==============================] - 98s 2s/step - loss: 0.4038 - accuracy: 0.8438 - val_loss: 0.5848 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.32234\n",
      "Epoch 40/40\n",
      "56/56 [==============================] - 105s 2s/step - loss: 0.4278 - accuracy: 0.8444 - val_loss: 0.6845 - val_accuracy: 0.7726\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.32234\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=nb_train_samples//batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\TOOLS\\Anaconda\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model=load_model('flower_detection_vgg_weight_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 54s 2s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(validation_generator,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the test data\n",
    "test_data = []\n",
    "test_labels = []\n",
    "batch_index = 0\n",
    "\n",
    "while batch_index <= validation_generator.batch_index:\n",
    "    data = next(validation_generator)\n",
    "    test_data.append(data[0])\n",
    "    test_labels.append(data[1])\n",
    "    batch_index = batch_index + 1\n",
    "\n",
    "test_data_array = np.asarray(test_data)\n",
    "test_labels_array = np.asarray(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-9873cf767e44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_labels_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(test_labels_array.argmax(axis=1), pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [23, 384]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-ece05517480f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Confusion Matrix'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Classification Report'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#target_names = list(class_labels.values())                                 #['class 0','class 1']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TOOLS\\Anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \"\"\"\n\u001b[1;32m--> 268\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TOOLS\\Anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \"\"\"\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TOOLS\\Anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 212\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [23, 384]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "Y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator, y_pred))\n",
    "print('Classification Report')\n",
    "#target_names = list(class_labels.values())                                 #['class 0','class 1']\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 3 1 1 0 3 1 4 4 3 2 2 2 4 0 0 2 1 1 1 1 3 0 2 3 2 0 4 0 3 2 4 2 2 4 1\n",
      " 1 2 4 3 4 4 2 0 4 4 3 0 2 0 2 4 3 1 1 3 3 2 0 1 4 0 2 2 1 2 0 2 1 0 2 2 4\n",
      " 3 1 0 0 3 3 1 4 1 4 1 4 0 1 4 2 4 1 0 2 2 1 1 4 3 3 3 3 0 1 1 1 0 2 1 1 4\n",
      " 0 2 1 2 4 4 1 4 4 3 2 3 0 4 4 1 1 1 1 4 2 0 2 3 1 2 1 3 4 1 4 1 4 2 4 4 2\n",
      " 1 0 3 3 4 4 1 3 2 3 0 0 4 4 1 2 1 0 1 0 2 1 3 4 4 4 2 1 3 0 2 3 3 1 0 1 2\n",
      " 1 2 2 4 2 2 3 3 2 0 2 4 4 0 0 2 1 4 2 0 4 4 0 1 4 4 2 0 2 1 4 2 2 4 1 0 3\n",
      " 2 4 2 4 1 3 0 0 0 0 4 3 2 1 4 1 3 4 2 0 0 0 4 1 2 1 2 0 4 1 2 0 4 1 1 2 4\n",
      " 3 0 4 1 1 0 1 4 3 0 3 4 1 1 4 3 4 2 1 2 0 0 0 3 1 1 2 1 4 1 2 2 4 1 4 2 0\n",
      " 2 3 1 0 1 3 4 4 2 3 4 4 3 1 3 1 2 3 2 2 4 4 4 1 1 2 2 0 2 3 1 3 1 1 2 2 4\n",
      " 1 2 0 4 1 1 3 4 2 4 2 3 1 0 0 2 4 2 0 3 1 1 4 0 3 1 4 2 2 1 2 0 1 1 0 4 0\n",
      " 1 4 0 3 3 1 4 2 2 0 2 0 1 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "Y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(validation_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.50954187e-01 1.92510188e-01 1.07734315e-01 1.03019506e-01\n",
      "  4.45781857e-01]\n",
      " [4.17751900e-04 2.66138086e-04 9.94633436e-01 8.32408783e-04\n",
      "  3.85034457e-03]\n",
      " [5.09345159e-03 1.63695496e-02 1.13276141e-02 9.26723123e-01\n",
      "  4.04862463e-02]\n",
      " ...\n",
      " [5.47592521e-01 3.68826181e-01 7.16519216e-03 6.79586679e-02\n",
      "  8.45741481e-03]\n",
      " [1.35862010e-05 9.99984980e-01 1.11639856e-07 1.23605707e-06\n",
      "  8.00767523e-08]\n",
      " [2.95371208e-02 2.22224202e-02 3.21436231e-03 9.38659370e-01\n",
      "  6.36673858e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
